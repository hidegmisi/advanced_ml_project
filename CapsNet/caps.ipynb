{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "NUM_CHANNELS = 5\n",
    "NUM_PC_OUTPUTS = NUM_CHANNELS * 36\n",
    "STEPS_PER_EPOCH = 500\n",
    "NUM_CLASSES = 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir = \"data\"\n",
    "test_dir = \"CapsNet/data/test\"\n",
    "train_dir = \"CapsNet/data/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 images belonging to 2 classes.\n",
      "Found 1043 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255, validation_split=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, class_mode='categorical', subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, class_mode='categorical', subset='validation'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capsule Layers\n",
    "class PrimaryCapsule(Layer):\n",
    "    def call(self, inputs):\n",
    "        s_norm = tf.norm(inputs, axis=-1, keepdims=True)\n",
    "        return (s_norm ** 2 / (1 + s_norm ** 2)) * (inputs / (s_norm + 1e-7))\n",
    "\n",
    "class DigitCapsule(Layer):\n",
    "    def call(self, inputs):\n",
    "        s = tf.reduce_sum(inputs, axis=1)\n",
    "        return PrimaryCapsule()(s)\n",
    "\n",
    "class Mapping(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = tf.Variable(tf.random.normal([NUM_PC_OUTPUTS, NUM_CLASSES, 8, 16]))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before reshape: (None, 56, 56, 128)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/alnuraabdyrova/advanced_ml_project/CapsNet/caps.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alnuraabdyrova/advanced_ml_project/CapsNet/caps.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     model \u001b[39m=\u001b[39m Model(inputs, outputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alnuraabdyrova/advanced_ml_project/CapsNet/caps.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alnuraabdyrova/advanced_ml_project/CapsNet/caps.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model \u001b[39m=\u001b[39m CapsNet()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alnuraabdyrova/advanced_ml_project/CapsNet/caps.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32m/Users/alnuraabdyrova/advanced_ml_project/CapsNet/caps.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alnuraabdyrova/advanced_ml_project/CapsNet/caps.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Debugging: Print shape before reshaping\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alnuraabdyrova/advanced_ml_project/CapsNet/caps.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mShape before reshape:\u001b[39m\u001b[39m\"\u001b[39m, x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alnuraabdyrova/advanced_ml_project/CapsNet/caps.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m x_shape \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mshape(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alnuraabdyrova/advanced_ml_project/CapsNet/caps.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(x, [x_shape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m8\u001b[39m]) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alnuraabdyrova/advanced_ml_project/CapsNet/caps.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m primary_caps \u001b[39m=\u001b[39m PrimaryCapsule()(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/dm/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/dm/lib/python3.11/site-packages/keras/src/backend/common/keras_tensor.py:156\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m__tf_tensor__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 156\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mused when constructing Keras Functional models \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand `keras.ops`). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are likely doing something like:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mx = Input(...)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m...\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtf_fn(x)  # Invalid.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclass MyLayer(Layer):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m    def call(self, x):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m        return tf_fn(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mx = MyLayer()(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CapsNet Model\n",
    "def CapsNet():\n",
    "    inputs = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    x = Conv2D(256, kernel_size=9, strides=1, activation='relu')(inputs)\n",
    "    x = Conv2D(128, kernel_size=9, strides=2, activation='relu')(x)\n",
    "    \n",
    "    # Debugging: Print shape before reshaping\n",
    "    print(\"Shape before reshape:\", x.shape)\n",
    "    \n",
    "    x_shape = tf.shape(x)\n",
    "    x = tf.reshape(x, [x_shape[0], -1, 8]) \n",
    "    \n",
    "    primary_caps = PrimaryCapsule()(x)\n",
    "    digit_caps_inputs = Mapping()(primary_caps)\n",
    "    outputs = DigitCapsule()(digit_caps_inputs)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = CapsNet()\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=NUM_EPOCHS, steps_per_epoch=STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
